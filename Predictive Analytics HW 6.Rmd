---
title: "Predictive Analytics HW 6"
author: "Rachel Jordan"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1

#### Describe the difference between bagging and boosting with trees.

Bagging is a random forest where m = p. Bagging uses bootstrap sampling to create copies of the training data set; each copy has a tree fit to it and then all the trees are combined. The trees are independent in bagging. In boosting, the trees are grown one at a time and each successive one uses info from the previous tree. When you boost, you fit a decision tree to the residuals from the current model and keep improving on the model by doing that over and over again with the residuals from previous models. This slower learning process can perform well, generally speaking.

## Question 2

#### This question uses the Caravan data set (from the R package ISLR2).

```{r}
#load data set
require(ISLR2)
caravan <- Caravan
```

#### (a) Create a training set consisting of the first 1,000 observations, and a test set consisting of the remaining observations.

```{r}
#recode response to 1 and 0
require(tidyverse)
caravan <- caravan %>% 
  mutate(Purchase2 = case_when(
    Purchase == "Yes" ~ 1,
    Purchase == "No" ~ 0,
  )) %>% 
  select(-Purchase)

#create test and training sets
train_caravan <- caravan[1:1000,]
test_caravan <- caravan[1001:5822,]
```

#### (b) Fit a boosting model to the training set with Purchase as the response and the other variables as predictors. Use 1,000 trees, and a shrinkage value of 0.01. Which predictors appear to be the most important?

```{r}
#load gbm package
require(gbm)

#set seed and fit boosting model on training set
set.seed (123)
boost_caravan <- gbm(Purchase2 ~ ., data = train_caravan, distribution = "bernoulli", n.trees = 1000, shrinkage=0.01)

#call summary
summary(boost_caravan)
```

PPERSAUT, MKOOPKLA, and MOPLHOOG seem to be the most influential variables.

#### (c) Use the boosting model to predict the response on the test data. Predict that a person will make a purchase if the estimated probability of purchase is greater than 20%. Form a confusion matrix. What fraction of the people predicted to make a purchase do in fact make one? How does this compare with the results obtained from applying KNN or logistic regression to this data set?

```{r}
#1 if p > 0.20, 0 if p >= 0.20
predictions <- ifelse(predict(boost_caravan, newdata = test_caravan, n.trees = 1000, type="response") > 0.20, 1, 0)

#confusion matrix
table(test_caravan$Purchase2, predictions)
```

The fraction of people predicted to make a purchase who end up actually making a purchase is 33/113= 29.2%.

```{r}
#applying knn
require(class)
knn_preds <- knn(train_caravan[,-86],test_caravan[,-86], cl=train_caravan[,86], k=5)

#confusion matrix
table(test_caravan$Purchase2, knn_preds)
```

Applying KNN where k=5 results in a fraction of 4/30 = 13.3%, much worse than the 29.2% result obtained by boosting.
